"""ç”¨RSL-RLå¼ºåŒ–å­¦ä¹ æ¡†æ¶æ¥è¿è¡Œå’Œæ¼”ç¤ºRLæ™ºèƒ½ä½“çš„è„šæœ¬ã€‚"""

import sys
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Literal, Optional, cast

import gymnasium as gym
import torch
import tyro
from rsl_rl.runners import OnPolicyRunner
from typing_extensions import assert_never

from mjlab.envs import ManagerBasedRlEnvCfg
from mjlab.rl import RslRlOnPolicyRunnerCfg, RslRlVecEnvWrapper
from mjlab.third_party.isaaclab.isaaclab_tasks.utils.parse_cfg import (
  load_cfg_from_registry,
)
from mjlab.utils.torch import configure_torch_backends
from mjlab.viewer import NativeMujocoViewer, ViserViewer

import mjlab.tasks  # è§¦å‘ä»»åŠ¡æ³¨å†Œ
import pygame

@dataclass(frozen=True)
class PlayConfig:
  """
  æ’­æ”¾/æ¼”ç¤ºé…ç½®æ•°æ®ç±»,å®šä¹‰äº†è¿è¡Œæ™ºèƒ½ä½“æ—¶çš„æ‰€æœ‰å‚æ•°ã€‚
  frozen=True è¡¨ç¤ºè¿™ä¸ªæ•°æ®ç±»æ˜¯ä¸å¯å˜çš„ã€‚
  """
  # æ™ºèƒ½ä½“ç±»å‹ï¼šzero(é›¶åŠ¨ä½œ), random(éšæœºåŠ¨ä½œ), trained(è®­ç»ƒå¥½çš„æ¨¡å‹)
  agent: Literal["zero", "random", "trained", "joystick"] = "trained"
  # æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ï¼Œç”¨äºåŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
  checkpoint_file: str | None = None
  # ç¯å¢ƒæ•°é‡ï¼Œå¦‚æœæŒ‡å®šåˆ™è¦†ç›–é…ç½®ä¸­çš„é»˜è®¤å€¼
  num_envs: int | None = None
  # è®¡ç®—è®¾å¤‡ï¼šcuda:0(GPU) æˆ– cpu
  device: str | None = None
  # æ˜¯å¦å½•åˆ¶è§†é¢‘
  video: bool = False
  # è§†é¢‘é•¿åº¦(æ­¥æ•°)
  video_length: int = 200
  # è§†é¢‘é«˜åº¦(åƒç´ )
  video_height: int | None = None
  # è§†é¢‘å®½åº¦(åƒç´ )
  video_width: int | None = None
  # æ‘„åƒæœºç¼–å·æˆ–åç§°
  camera: int | str | None = None
  # æŸ¥çœ‹å™¨ç±»å‹ï¼šnative(åŸç”ŸMuJoCoæŸ¥çœ‹å™¨) æˆ– viser(WebæŸ¥çœ‹å™¨)
  viewer: Literal["native", "viser"] = "native"
  
  # ğŸ® æ‰‹æŸ„é…ç½®å‚æ•°
  joystick_id: int = 0  # æ‰‹æŸ„è®¾å¤‡IDï¼ˆå¦‚æœæœ‰å¤šä¸ªæ‰‹æŸ„ï¼‰
  joystick_deadzone: float = 0.1  # æ‘‡æ†æ­»åŒºï¼ˆé¿å…æ¼‚ç§»ï¼‰
  joystick_scale: float = 1.0  # åŠ¨ä½œç¼©æ”¾ç³»æ•°
  debug_joystick: bool = True  # ğŸ†• æ˜¯å¦å¯ç”¨æ‰‹æŸ„è°ƒè¯•æ‰“å°

class PolicyJoystick:
  """
  ä½¿ç”¨æ¸¸æˆæ‰‹æŸ„æ§åˆ¶æœºå™¨äººçš„ç­–ç•¥ï¼ˆæ··åˆæ§åˆ¶æ¨¡å¼ï¼‰
  
  ç­–ç•¥æ¶æ„ï¼š
    æ‰‹æŸ„ â†’ é«˜å±‚è¿åŠ¨æŒ‡ä»¤(vx, vy, vyaw) â†’ è®­ç»ƒå¥½çš„RLç­–ç•¥ â†’ å…³èŠ‚åŠ¨ä½œ
  
  æ”¯æŒçš„æ‰‹æŸ„æ˜ å°„ï¼š
  - å·¦æ‘‡æ†å‚ç›´è½´ (Axis 1): å‰è¿›/åé€€é€Ÿåº¦ (vx)
  - å·¦æ‘‡æ†æ°´å¹³è½´ (Axis 0): å·¦å³å¹³ç§»é€Ÿåº¦ (vy)  
  - å³æ‘‡æ†æ°´å¹³è½´ (Axis 2): è½¬å‘é€Ÿåº¦ (vyaw)
  """
  
  def __init__(
    self, 
    trained_policy,  # ğŸ”‘ å…³é”®ï¼šéœ€è¦è®­ç»ƒå¥½çš„ç­–ç•¥
    device: str,
    joystick_id: int = 0,
    deadzone: float = 0.15,
    max_lin_vel: float = 1.0,  # æœ€å¤§çº¿é€Ÿåº¦ (m/s)
    max_ang_vel: float = 1.0,  # æœ€å¤§è§’é€Ÿåº¦ (rad/s)
    debug: bool = True,  # ğŸ†• è°ƒè¯•æ¨¡å¼å¼€å…³
  ):
    
    self.trained_policy = trained_policy
    self.device = device
    self.deadzone = deadzone
    self.max_lin_vel = max_lin_vel
    self.max_ang_vel = max_ang_vel
    self.debug = debug  # ğŸ†•
    self.step_count = 0  # ğŸ†• æ­¥æ•°è®¡æ•°å™¨
    
    # åˆå§‹åŒ– pygame å’Œæ‰‹æŸ„
    pygame.init()
    pygame.joystick.init()
    
    # æ£€æŸ¥æ‰‹æŸ„è¿æ¥
    joystick_count = pygame.joystick.get_count()
    if joystick_count == 0:
        raise RuntimeError("âŒ No joystick detected! Please connect a controller.")
    
    if joystick_id >= joystick_count:
        raise ValueError(
            f"âŒ Joystick ID {joystick_id} not found. "
            f"Available IDs: 0-{joystick_count-1}"
        )
    
    # è¿æ¥æ‰‹æŸ„
    self.joystick = pygame.joystick.Joystick(joystick_id)
    self.joystick.init()
    
    # ğŸ†• è·å–æ‰‹æŸ„çš„è½´å’ŒæŒ‰é’®æ•°é‡
    self.num_axes = self.joystick.get_numaxes()
    self.num_buttons = self.joystick.get_numbuttons()
    
    # æ‰“å°æ‰‹æŸ„ä¿¡æ¯
    print(f"\n{'='*60}")
    print(f"ğŸ® Joystick Control Mode (Hybrid)")
    print(f"{'='*60}")
    print(f"  Controller: {self.joystick.get_name()}")
    print(f"  Axes: {self.num_axes}")
    print(f"  Buttons: {self.num_buttons}")
    print(f"")
    print(f"  ğŸ“‹ Control Mapping:")
    print(f"     Left Stick Y  (Axis 1) â†’ Forward/Backward (vx)")
    print(f"     Left Stick X  (Axis 0) â†’ Left/Right (vy)")
    print(f"     Right Stick X (Axis 2) â†’ Rotate (vyaw)")
    print(f"")
    print(f"  âš™ï¸  Parameters:")
    print(f"     Max Linear Velocity:  {max_lin_vel} m/s")
    print(f"     Max Angular Velocity: {max_ang_vel} rad/s")
    print(f"     Deadzone: {deadzone}")
    print(f"     Debug Mode: {'âœ… ENABLED' if debug else 'âŒ DISABLED'}")
    print(f"{'='*60}\n")
    
    # ğŸ†• æµ‹è¯•æ‰‹æŸ„åˆå§‹è¯»å–
    print("ğŸ” Testing initial joystick read...")
    self._test_joystick_read()
        
  def _apply_deadzone(self, value: float) -> float:
      """åº”ç”¨æ­»åŒºï¼Œé¿å…æ‘‡æ†æ¼‚ç§»"""
      if abs(value) < self.deadzone:
          return 0.0
      # é‡æ–°æ˜ å°„åˆ° [-1, 1] èŒƒå›´
      sign = 1 if value > 0 else -1
      return sign * (abs(value) - self.deadzone) / (1.0 - self.deadzone)
  
  def _test_joystick_read(self):
    """ğŸ†• æµ‹è¯•æ‰‹æŸ„è¯»å–åŠŸèƒ½"""
    try:
      pygame.event.pump()
      print("  âœ… pygame.event.pump() successful")
      
      # è¯»å–æ‰€æœ‰è½´çš„å€¼
      print(f"  ğŸ“Š All axes values:")
      for i in range(self.num_axes):
        axis_val = self.joystick.get_axis(i)
        print(f"     Axis {i}: {axis_val:+.4f}")
      
      # è¯»å–æ‰€æœ‰æŒ‰é’®çŠ¶æ€
      print(f"  ğŸ”˜ All button states:")
      pressed_buttons = [i for i in range(self.num_buttons) if self.joystick.get_button(i)]
      if pressed_buttons:
        print(f"     Pressed: {pressed_buttons}")
      else:
        print(f"     None pressed")
      
      print("  âœ… Joystick test completed\n")
    except Exception as e:
      print(f"  âŒ Joystick test failed: {e}\n")
  
  def _read_velocity_command(self) -> torch.Tensor:
    """
    è¯»å–æ‰‹æŸ„çŠ¶æ€å¹¶è½¬æ¢ä¸ºé€Ÿåº¦æŒ‡ä»¤
    
    Returns:
        velocity_cmd: å½¢çŠ¶ä¸º (num_envs, 3) çš„å¼ é‡ [vx, vy, vyaw]
    """
    # æ›´æ–°æ‰‹æŸ„çŠ¶æ€
    pygame.event.pump()
    
    # ğŸ†• è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºå½“å‰æ­¥æ•°
    if self.debug and self.step_count % 50 == 0:  # æ¯50æ­¥æ‰“å°ä¸€æ¬¡è¯¦ç»†ä¿¡æ¯
      print(f"\n{'â”€'*60}")
      print(f"ğŸ” DEBUG [Step {self.step_count}] - Joystick State")
      print(f"{'â”€'*60}")
    
    # è¯»å–æ‘‡æ†è½´ï¼ˆæ³¨æ„ï¼šæŸäº›æ‰‹æŸ„çš„Yè½´æ˜¯åçš„ï¼‰
    # Axis 1: å·¦æ‘‡æ†å‚ç›´ï¼ˆå‰è¿›/åé€€ï¼‰- é€šå¸¸éœ€è¦åè½¬
    raw_vx = -self.joystick.get_axis(1) if self.num_axes > 1 else 0.0
    # Axis 0: å·¦æ‘‡æ†æ°´å¹³ï¼ˆå·¦å³å¹³ç§»ï¼‰
    raw_vy = self.joystick.get_axis(0) if self.num_axes > 0 else 0.0
    # Axis 2 æˆ– 3: å³æ‘‡æ†æ°´å¹³ï¼ˆè½¬å‘ï¼‰
    raw_vyaw = self.joystick.get_axis(3) if self.num_axes > 2 else 0.0
    
    # ğŸ†• è¯¦ç»†è°ƒè¯•æ‰“å°
    if self.debug and self.step_count % 50 == 0:
      print(f"  ğŸ“¥ Raw Axis Values:")
      print(f"     Axis 0 (Left X):  {self.joystick.get_axis(0):+.4f}")
      print(f"     Axis 1 (Left Y):  {self.joystick.get_axis(1):+.4f}")
      if self.num_axes > 2:
        print(f"     Axis 2 (Right X): {self.joystick.get_axis(2):+.4f}")
      if self.num_axes > 3:
        print(f"     Axis 3 (Right Y): {self.joystick.get_axis(3):+.4f}")
      
      print(f"\n  ğŸ¯ Mapped Raw Values (before deadzone):")
      print(f"     raw_vx:   {raw_vx:+.4f}")
      print(f"     raw_vy:   {raw_vy:+.4f}")
      print(f"     raw_vyaw: {raw_vyaw:+.4f}")
    
    # åº”ç”¨æ­»åŒº
    vx_normalized = self._apply_deadzone(raw_vx)
    vy_normalized = self._apply_deadzone(raw_vy)
    vyaw_normalized = self._apply_deadzone(raw_vyaw)
    
    # ç¼©æ”¾åˆ°å®é™…é€Ÿåº¦
    vx = vx_normalized * self.max_lin_vel
    vy = -vy_normalized * self.max_lin_vel
    vyaw = -vyaw_normalized * self.max_ang_vel
    
    # ğŸ†• è¯¦ç»†è°ƒè¯•æ‰“å°
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  âš™ï¸  After Deadzone ({self.deadzone}):")
      print(f"     vx_norm:   {vx_normalized:+.4f}")
      print(f"     vy_norm:   {vy_normalized:+.4f}")
      print(f"     vyaw_norm: {vyaw_normalized:+.4f}")
      
      print(f"\n  ğŸš€ Final Velocity Commands:")
      print(f"     vx:   {vx:+.4f} m/s  (max: Â±{self.max_lin_vel})")
      print(f"     vy:   {vy:+.4f} m/s  (max: Â±{self.max_lin_vel})")
      print(f"     vyaw: {vyaw:+.4f} rad/s (max: Â±{self.max_ang_vel})")
      print(f"{'â”€'*60}\n")
    
    # ğŸ†• å®æ—¶ç®€åŒ–æ‰“å°ï¼ˆæ¯æ­¥éƒ½æ˜¾ç¤ºï¼Œä½†åªåœ¨æœ‰æ˜æ˜¾è¾“å…¥æ—¶ï¼‰
    if self.debug and (abs(vx) > 0.01 or abs(vy) > 0.01 or abs(vyaw) > 0.01):
      print(f"\rğŸ® [Step {self.step_count:4d}] Command: "
            f"vx={vx:+.2f} vy={vy:+.2f} vyaw={vyaw:+.2f}  ", end="")
    elif self.debug and self.step_count % 100 == 0:
      # å³ä½¿æ²¡æœ‰è¾“å…¥ï¼Œä¹Ÿå®šæœŸæ˜¾ç¤ºçŠ¶æ€
      print(f"\rğŸ® [Step {self.step_count:4d}] Command: "
            f"vx={vx:+.2f} vy={vy:+.2f} vyaw={vyaw:+.2f} (idle)", end="")
    
    return torch.tensor([vx, vy, vyaw], device=self.device)
    
  def __call__(self, obs: dict) -> torch.Tensor:
    """
    ç­–ç•¥è°ƒç”¨æ¥å£ï¼ˆæ··åˆæ§åˆ¶æ¨¡å¼ï¼‰
    
    æµç¨‹ï¼š
      1. ä»æ‰‹æŸ„è¯»å–é€Ÿåº¦æŒ‡ä»¤
      2. ä¿®æ”¹è§‚æµ‹ä¸­çš„ command å­—æ®µ
      3. è°ƒç”¨è®­ç»ƒå¥½çš„ç­–ç•¥ç”Ÿæˆå…³èŠ‚åŠ¨ä½œ
    
    Args:
        obs: ç¯å¢ƒè§‚æµ‹å€¼å­—å…¸ï¼ŒåŒ…å« 'policy' é”®
    
    Returns:
        åŠ¨ä½œå¼ é‡ï¼Œç”±è®­ç»ƒå¥½çš„ç­–ç•¥ç”Ÿæˆ
    """
    # ğŸ†• æ­¥æ•°è®¡æ•°
    self.step_count += 1
    
    # ğŸ†• è°ƒè¯•ï¼šæ˜¾ç¤ºåŸå§‹è§‚æµ‹ä¿¡æ¯
    if self.debug and self.step_count % 50 == 0:
      print(f"\n{'â•'*60}")
      print(f"ğŸ§  DEBUG [Step {self.step_count}] - Policy Call")
      print(f"{'â•'*60}")
      print(f"  ğŸ“Š Original Observation:")
      print(f"     obs['policy'] shape: {obs['policy'].shape}")
      print(f"     obs['policy'] device: {obs['policy'].device}")
      print(f"     Original command (last 3 dims): {obs['policy'][0, -3:].cpu().numpy()}")
    
    # è¯»å–æ‰‹æŸ„æŒ‡ä»¤
    velocity_cmd = self._read_velocity_command()
    
    # ğŸ†• è°ƒè¯•ï¼šæ˜¾ç¤ºè¯»å–çš„é€Ÿåº¦æŒ‡ä»¤
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  ğŸ® Joystick Velocity Command:")
      print(f"     velocity_cmd: {velocity_cmd.cpu().numpy()}")
      print(f"     velocity_cmd device: {velocity_cmd.device}")
    
    # ğŸ”‘ å…³é”®ï¼šä¿®æ”¹è§‚æµ‹ä¸­çš„ command éƒ¨åˆ†
    obs_policy = obs['policy'].clone()  # é¿å…ä¿®æ”¹åŸå§‹è§‚æµ‹
    
    # è·å–ç¯å¢ƒæ•°é‡
    num_envs = obs_policy.shape[0]
    
    # ğŸ†• è°ƒè¯•ï¼šæ˜¾ç¤ºç¯å¢ƒä¿¡æ¯
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  ğŸŒ Environment Info:")
      print(f"     num_envs: {num_envs}")
    
    # å°†æ‰‹æŸ„æŒ‡ä»¤å¹¿æ’­åˆ°æ‰€æœ‰ç¯å¢ƒ
    velocity_cmd_batch = velocity_cmd.unsqueeze(0).repeat(num_envs, 1)
    
    # ğŸ†• è°ƒè¯•ï¼šæ˜¾ç¤ºå¹¿æ’­åçš„æŒ‡ä»¤
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  ğŸ“¡ Broadcast Command:")
      print(f"     velocity_cmd_batch shape: {velocity_cmd_batch.shape}")
      print(f"     First env command: {velocity_cmd_batch[0].cpu().numpy()}")
      if num_envs > 1:
        print(f"     Last env command:  {velocity_cmd_batch[-1].cpu().numpy()}")
    
    # æ›¿æ¢è§‚æµ‹ä¸­çš„ command éƒ¨åˆ†ï¼ˆæœ€å3ä¸ªç»´åº¦ï¼‰
    old_command = obs_policy[0, -3:].clone()  # ğŸ†• ä¿å­˜æ—§å€¼ç”¨äºå¯¹æ¯”
    obs_policy[:, -3:] = velocity_cmd_batch
    
    # ğŸ†• è°ƒè¯•ï¼šå¯¹æ¯”ä¿®æ”¹å‰å
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  ğŸ”„ Command Replacement:")
      print(f"     Old command: {old_command.cpu().numpy()}")
      print(f"     New command: {obs_policy[0, -3:].cpu().numpy()}")
      print(f"     âœ… Command replaced successfully!")
    
    # ä½¿ç”¨ä¿®æ”¹åçš„è§‚æµ‹è°ƒç”¨è®­ç»ƒå¥½çš„ç­–ç•¥
    modified_obs = {'policy': obs_policy}
    if 'critic' in obs:
      modified_obs['critic'] = obs['critic']
    
    # ğŸ†• è°ƒè¯•ï¼šæ˜¾ç¤ºå³å°†ä¼ å…¥ç­–ç•¥çš„è§‚æµ‹
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  ğŸ§ª Modified Observation to Policy:")
      print(f"     modified_obs keys: {list(modified_obs.keys())}")
      print(f"     Command in modified_obs: {modified_obs['policy'][0, -3:].cpu().numpy()}")
    
    # è°ƒç”¨è®­ç»ƒå¥½çš„ç­–ç•¥
    action = self.trained_policy(modified_obs)
    
    # ğŸ†• è°ƒè¯•ï¼šæ˜¾ç¤ºè¾“å‡ºåŠ¨ä½œ
    if self.debug and self.step_count % 50 == 0:
      print(f"\n  ğŸ¯ Policy Output:")
      print(f"     action shape: {action.shape}")
      print(f"     action range: [{action.min().item():.4f}, {action.max().item():.4f}]")
      print(f"     action mean: {action.mean().item():.4f}")
      print(f"     action std: {action.std().item():.4f}")
      print(f"{'â•'*60}\n")
    
    return action
  
  def __del__(self):
    """ææ„å‡½æ•°ï¼šæ¸…ç† pygame èµ„æº"""
    if hasattr(self, 'joystick'):
      self.joystick.quit()
    pygame.quit()
    if self.debug:
      print("\nğŸ® Joystick disconnected and cleaned up")


def run_play(task: str, cfg: PlayConfig):
  """
  ä¸»è¦å‡½æ•°ï¼šåˆå§‹åŒ–ç¯å¢ƒï¼ŒåŠ è½½æ™ºèƒ½ä½“ç­–ç•¥ï¼Œå¹¶è¿è¡Œæ¼”ç¤ºå¾ªç¯ã€‚
  
  å‚æ•°ï¼š
    task: ä»»åŠ¡åç§°(å¦‚ "Mjlab-HumanoidTask-v0")
    cfg: PlayConfigå¯¹è±¡ï¼ŒåŒ…å«æ‰€æœ‰é…ç½®å‚æ•°
  """
  # é…ç½®PyTorchåç«¯ä»¥è·å¾—æœ€ä½³æ€§èƒ½
  configure_torch_backends()

  # ç¡®å®šä½¿ç”¨çš„è®¡ç®—è®¾å¤‡(GPUæˆ–CPU)
  device = cfg.device or ("cuda:0" if torch.cuda.is_available() else "cpu")
  print(f"[INFO]: Using device: {device}")

  # ä»æ³¨å†Œè¡¨åŠ è½½ç¯å¢ƒé…ç½®
  env_cfg = cast(
    ManagerBasedRlEnvCfg, load_cfg_from_registry(task, "env_cfg_entry_point")
  )
  # ä»æ³¨å†Œè¡¨åŠ è½½å¼ºåŒ–å­¦ä¹ æ™ºèƒ½ä½“é…ç½®
  agent_cfg = cast(
    RslRlOnPolicyRunnerCfg, load_cfg_from_registry(task, "rl_cfg_entry_point")
  )

  # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨è™šæ‹Ÿæ¨¡å¼(zeroæˆ–random)
  DUMMY_MODE = cfg.agent in {"zero", "random"}
  # åˆ¤æ–­æ˜¯å¦ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹
  TRAINED_MODE = not DUMMY_MODE
  # ğŸ†• åˆ¤æ–­æ˜¯å¦ä½¿ç”¨æ‰‹æŸ„æ¨¡å¼
  JOYSTICK_MODE = cfg.agent == "joystick"

  # æ—¥å¿—ç›®å½•è·¯å¾„
  log_dir: Optional[Path] = None
  # æ¢å¤/æ£€æŸ¥ç‚¹è·¯å¾„
  resume_path: Optional[Path] = None
  
  # å¦‚æœä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹æˆ–æ‰‹æŸ„æ¨¡å¼ï¼Œå¤„ç†æ£€æŸ¥ç‚¹åŠ è½½é€»è¾‘
  if TRAINED_MODE or JOYSTICK_MODE:
    # æ„å»ºæ—¥å¿—æ ¹ç›®å½•è·¯å¾„(logs/rsl_rl/å®éªŒåç§°)
    log_root_path = (Path("logs") / "rsl_rl" / agent_cfg.experiment_name).resolve()
    print(f"[INFO]: Loading experiment from: {log_root_path}")
    
    # å¦‚æœæŒ‡å®šäº†æ£€æŸ¥ç‚¹æ–‡ä»¶
    if cfg.checkpoint_file is not None:
      resume_path = Path(cfg.checkpoint_file)
      # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
      if not resume_path.exists():
        raise FileNotFoundError(f"Checkpoint file not found: {resume_path}")
    else:
      # ä½¿ç”¨è®­ç»ƒæ¨¡å¼ä½†æœªæŒ‡å®šæ£€æŸ¥ç‚¹æ–‡ä»¶æ—¶ï¼ŒæŠ›å‡ºé”™è¯¯
      raise ValueError(
        "`checkpoint_file` is required when using trained agent."
      )
    
    print(f"[INFO]: Loading checkpoint: {resume_path}")
    # è®¾ç½®æ—¥å¿—ç›®å½•ä¸ºæ£€æŸ¥ç‚¹çš„çˆ¶ç›®å½•
    log_dir = resume_path.parent

  # å¦‚æœæŒ‡å®šäº†ç¯å¢ƒæ•°é‡ï¼Œè¦†ç›–é…ç½®ä¸­çš„å€¼
  if cfg.num_envs is not None:
    env_cfg.scene.num_envs = cfg.num_envs
  # å¦‚æœæŒ‡å®šäº†è§†é¢‘é«˜åº¦ï¼Œè¦†ç›–é…ç½®ä¸­çš„å€¼
  if cfg.video_height is not None:
    env_cfg.viewer.height = cfg.video_height
  # å¦‚æœæŒ‡å®šäº†è§†é¢‘å®½åº¦ï¼Œè¦†ç›–é…ç½®ä¸­çš„å€¼
  if cfg.video_width is not None:
    env_cfg.viewer.width = cfg.video_width

  # ç¡®å®šæ¸²æŸ“æ¨¡å¼
  render_mode = "rgb_array" if ((TRAINED_MODE or JOYSTICK_MODE) and cfg.video) else None
  # è™šæ‹Ÿæ¨¡å¼ä¸‹ä¸æ”¯æŒè§†é¢‘å½•åˆ¶
  if cfg.video and DUMMY_MODE:
    print(
      "[WARN] Video recording with dummy agents is disabled (no checkpoint/log_dir)."
    )
  
  # åˆ›å»ºGymnasiumç¯å¢ƒå®ä¾‹
  env = gym.make(task, cfg=env_cfg, device=device, render_mode=render_mode)

  # å¦‚æœéœ€è¦å½•åˆ¶è§†é¢‘ï¼Œç”¨RecordVideoåŒ…è£…ç¯å¢ƒ
  if (TRAINED_MODE or JOYSTICK_MODE) and cfg.video:
    print("[INFO] Recording videos during play")
    env = gym.wrappers.RecordVideo(
      env,
      video_folder=str(Path(log_dir) / "videos" / "play"),  # type: ignore[arg-type]
      step_trigger=lambda step: step == 0,
      video_length=cfg.video_length,
      disable_logger=True,
    )

  # ç”¨RSL-RLå‘é‡ç¯å¢ƒåŒ…è£…å™¨åŒ…è£…ç¯å¢ƒ
  env = RslRlVecEnvWrapper(env, clip_actions=agent_cfg.clip_actions)
  
  # æ ¹æ®æ™ºèƒ½ä½“ç±»å‹åˆ›å»ºç›¸åº”çš„ç­–ç•¥å¯¹è±¡
  if DUMMY_MODE:
    # è·å–ç¯å¢ƒçš„åŠ¨ä½œç©ºé—´ç»´åº¦
    action_shape: tuple[int, ...] = env.unwrapped.action_space.shape  # type: ignore
    
    if cfg.agent == "zero":
      # é›¶ç­–ç•¥ï¼šå§‹ç»ˆè¿”å›é›¶åŠ¨ä½œ
      class PolicyZero:
        def __call__(self, obs) -> torch.Tensor:
          del obs
          return torch.zeros(action_shape, device=env.unwrapped.device)

      policy = PolicyZero()
    elif cfg.agent == "random":
      class PolicyRandom:
        def __call__(self, obs) -> torch.Tensor:
          del obs
          return 2 * torch.rand(action_shape, device=env.unwrapped.device) - 1
      policy = PolicyRandom()
    else:
      raise ValueError(f"Unknown agent type: {cfg.agent}")
  elif JOYSTICK_MODE:
    # âœ… æ‰‹æŸ„æ¨¡å¼ï¼šåŠ è½½è®­ç»ƒå¥½çš„ç­–ç•¥ååŒ…è£…
    print("\n[INFO] Initializing joystick control mode...")
    runner = OnPolicyRunner(
      env, 
      asdict(agent_cfg),
      log_dir=str(log_dir), 
      device=device
    )
    print("[INFO] Loading trained policy...")
    runner.load(str(resume_path), map_location=device)
    trained_policy = runner.get_inference_policy(device=device)
    print("[INFO] Trained policy loaded successfully")
    
    print("[INFO] Creating joystick policy wrapper...")
    policy = PolicyJoystick(
      trained_policy=trained_policy,
      device=env.unwrapped.device,
      joystick_id=cfg.joystick_id,
      deadzone=cfg.joystick_deadzone,
      max_lin_vel=1.5,
      max_ang_vel=1.0,
      debug=cfg.debug_joystick,  # ğŸ†• ä½¿ç”¨é…ç½®ä¸­çš„è°ƒè¯•å¼€å…³
    )
    print("[INFO] âœ… Joystick policy wrapper created successfully\n")
  else:
    # å¦‚æœä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ŒåŠ è½½è®­ç»ƒå¥½çš„ç­–ç•¥
    print("\n[INFO] Loading trained policy...")
    # åˆ›å»ºOnPolicyè®­ç»ƒå™¨è¿è¡Œå™¨å®ä¾‹
    runner = OnPolicyRunner(
      env, 
      asdict(agent_cfg),  # å°†é…ç½®æ•°æ®ç±»è½¬æ¢ä¸ºå­—å…¸
      log_dir=str(log_dir), 
      device=device
    )
    # ä»æ£€æŸ¥ç‚¹æ–‡ä»¶åŠ è½½è®­ç»ƒå¥½çš„æƒé‡
    runner.load(str(resume_path), map_location=device)
    # æå–æ¨ç†ç­–ç•¥(ä¸éœ€è¦æ¢¯åº¦è®¡ç®—)
    policy = runner.get_inference_policy(device=device)
    print("[INFO] âœ… Trained policy loaded successfully\n")

  # ğŸ†• åœ¨è¿è¡Œå‰æ·»åŠ æ‰‹æŸ„æµ‹è¯•æç¤º
  if JOYSTICK_MODE:
    print("\n" + "="*60)
    print("ğŸ® JOYSTICK TEST MODE")
    print("="*60)
    print("  Please move the joystick sticks to test:")
    print("  - Left stick: Should control vx (forward/backward) and vy (left/right)")
    print("  - Right stick: Should control vyaw (rotation)")
    print("  ")
    print("  The debug output will show:")
    print("  1. Raw axis values from joystick")
    print("  2. Values after deadzone filtering")
    print("  3. Final velocity commands")
    print("  4. How observations are modified")
    print("  5. Actions generated by the policy")
    print("="*60)
    input("\n  Press ENTER to start... ")
    print("\n")

  # æ ¹æ®é…ç½®é€‰æ‹©ä½¿ç”¨çš„æŸ¥çœ‹å™¨è¿è¡Œæ¼”ç¤º
  if cfg.viewer == "native":
    # ä½¿ç”¨åŸç”ŸMuJoCoæŸ¥çœ‹å™¨è¿›è¡Œäº¤äº’å¼å¯è§†åŒ–
    print("[INFO] Starting Native MuJoCo Viewer...")
    NativeMujocoViewer(env, policy).run()
  elif cfg.viewer == "viser":
    # ä½¿ç”¨Viser WebæŸ¥çœ‹å™¨è¿›è¡Œå¯è§†åŒ–
    print("[INFO] Starting Viser Web Viewer...")
    ViserViewer(env, policy).run()
  else:
    # ç±»å‹æ£€æŸ¥ï¼šå¦‚æœviewerå€¼æ— æ•ˆï¼Œå¼•å‘é”™è¯¯
    assert_never(cfg.viewer)

  # å…³é—­ç¯å¢ƒï¼Œé‡Šæ”¾èµ„æº
  env.close()


def main():
  """
  ä¸»å…¥å£ç‚¹ï¼šè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è¿è¡Œæ¼”ç¤ºã€‚
  
  è¯¥å‡½æ•°åˆ†ä¸¤æ­¥è§£æå‘½ä»¤è¡Œå‚æ•°ï¼š
  1. ç¬¬ä¸€æ­¥ï¼šé€‰æ‹©ä»»åŠ¡(ä»¥ "Mjlab-" å¼€å¤´çš„ä»»åŠ¡)
  2. ç¬¬äºŒæ­¥ï¼šè§£æPlayConfigé…ç½®å‚æ•°
  """
  # ä»»åŠ¡åç§°å‰ç¼€
  task_prefix = "Mjlab-"
  
  # ç¬¬ä¸€æ­¥ï¼šè§£æç¬¬ä¸€ä¸ªå‚æ•°ä½œä¸ºä»»åŠ¡é€‰æ‹©
  # åªæ˜¾ç¤ºä»¥ "Mjlab-" å¼€å¤´çš„ä»»åŠ¡ä¾›ç”¨æˆ·é€‰æ‹©
  chosen_task, remaining_args = tyro.cli(
    tyro.extras.literal_type_from_choices(
      [k for k in gym.registry.keys() if k.startswith(task_prefix)]
    ),
    add_help=False,  # ä¸æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯(ç”±ä¸»ç¨‹åºå¤„ç†)
    return_unknown_args=True,  # è¿”å›å‰©ä½™æœªè§£æçš„å‚æ•°
  )
  del task_prefix

  # ç¬¬äºŒæ­¥ï¼šè§£æå‰©ä½™çš„å‘½ä»¤è¡Œå‚æ•°ä¸ºPlayConfigå¯¹è±¡
  args = tyro.cli(
    PlayConfig,
    args=remaining_args,  # ä½¿ç”¨å‰©ä½™çš„å‚æ•°
    default=PlayConfig(),  # ä½¿ç”¨PlayConfigçš„é»˜è®¤å€¼
    prog=sys.argv[0] + f" {chosen_task}",  # ç¨‹åºå¸®åŠ©ä¿¡æ¯å‰ç¼€
    config=(
      tyro.conf.AvoidSubcommands,  # é¿å…å­å‘½ä»¤
      tyro.conf.FlagConversionOff,  # å…³é—­æ ‡å¿—è½¬æ¢
    ),
  )
  del remaining_args

  # è¿è¡Œæ¼”ç¤º
  run_play(chosen_task, args)


# è„šæœ¬å…¥å£ç‚¹
if __name__ == "__main__":
  main()
